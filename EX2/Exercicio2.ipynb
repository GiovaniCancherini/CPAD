{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping IMDb - Top 250 Séries\n",
    "\n",
    "### Grupo: Giovani Cancherini, Eduardo Traunig, Vinicius Quintian, João Pedro Fossa\n",
    "### Data de Entrega: 23/04/2024 (Turma 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 1 - Obter as 250 melhores séries do IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_filename(filename):\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '_', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Executa em modo headless\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), \n",
    "                             options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_top_250_series():\n",
    "    driver = setup_driver()\n",
    "    url = \"https://www.imdb.com/chart/toptv/\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Espera a página carregar\n",
    "    \n",
    "    series_list = []\n",
    "    \n",
    "    series_elements = driver.find_elements(By.CSS_SELECTOR, \".ipc-metadata-list-summary-item__c\")\n",
    "    \n",
    "    for serie in series_elements[:250]:  # Limita às 250 primeiras\n",
    "        try:\n",
    "            # Extrai título\n",
    "            title_element = sanitize_filename(serie.find_element(By.CSS_SELECTOR, \"h3.ipc-title__text\"))\n",
    "            title = title_element.text.split('. ', 1)[1]  # Remove o número do ranking\n",
    "            \n",
    "            # Extrai ano e duração\n",
    "            metadata = serie.find_element(By.CSS_SELECTOR, \".cli-title-metadata\")\n",
    "            year = metadata.find_elements(By.TAG_NAME, \"span\")[0].text\n",
    "            episodes = sanitize_filename(metadata.find_elements(By.TAG_NAME, \"span\")[1].text) if len(metadata.find_elements(By.TAG_NAME, \"span\")) > 1 else \"N/A\"\n",
    "            \n",
    "            # Extrai nota\n",
    "            rating_element = serie.find_element(By.CSS_SELECTOR, \"[data-testid='ratingGroup--imdb-rating']\")\n",
    "            rating = rating_element.text.split('(')[0].strip()\n",
    "            \n",
    "            # Extrai link\n",
    "            link = serie.find_element(By.CSS_SELECTOR, \"a.ipc-title-link-wrapper\").get_attribute(\"href\")\n",
    "            \n",
    "            series_data = {\n",
    "                \"title\": title,\n",
    "                \"year\": int(year) if year.isdigit() else year,\n",
    "                \"episodes\": episodes,\n",
    "                \"rating\": float(rating) if rating.replace('.', '').isdigit() else rating,\n",
    "                \"url\": link\n",
    "            }\n",
    "            \n",
    "            series_list.append(series_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao extrair dados da série: {e}\")\n",
    "            continue\n",
    "    \n",
    "    driver.quit()\n",
    "    return series_list\n",
    "\n",
    "top_series = scrape_top_250_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_series_data(series_data):\n",
    "    os.makedirs(\"imdb_data\", exist_ok=True)\n",
    "    with open(\"imdb_data/top_250_series.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(series_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a coleta das 250 melhores séries\n",
    "top_series = scrape_top_250_series()\n",
    "save_series_data(top_series)\n",
    "print(f\"Dados de {len(top_series)} séries coletados e salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2 - Obter detalhes adicionais de cada série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_series_details(series_list):\n",
    "    driver = setup_driver()\n",
    "    \n",
    "    for serie in series_list:\n",
    "        try:\n",
    "            driver.get(serie[\"url\"])\n",
    "            time.sleep(2)  # Espera para evitar bloqueio\n",
    "            \n",
    "            # Extrai popularidade\n",
    "            try:\n",
    "                popularity = driver.find_element(By.XPATH, \"//div[contains(text(),'Popularity')]/following-sibling::div\").text\n",
    "                serie[\"popularity\"] = int(popularity.replace(',', '')) if popularity.replace(',', '').isdigit() else popularity\n",
    "            except:\n",
    "                serie[\"popularity\"] = \"N/A\"\n",
    "            \n",
    "            # Extrai elenco principal\n",
    "            try:\n",
    "                cast_section = driver.find_element(By.CSS_SELECTOR, \"section[data-testid='title-cast']\")\n",
    "                cast_elements = cast_section.find_elements(By.CSS_SELECTOR, \".ipc-metadata-list__item\")\n",
    "                \n",
    "                cast_list = []\n",
    "                for cast in cast_elements[:10]:  # Limita aos 10 primeiros\n",
    "                    actor = cast.find_element(By.CSS_SELECTOR, \"[data-testid='title-cast-item__actor']\").text\n",
    "                    character = cast.find_element(By.CSS_SELECTOR, \"[data-testid='title-cast-item__character']\").text\n",
    "                    cast_list.append({\"actor\": actor, \"character\": character})\n",
    "                \n",
    "                serie[\"cast\"] = cast_list\n",
    "            except:\n",
    "                serie[\"cast\"] = []\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao extrair detalhes de {serie['title']}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    driver.quit()\n",
    "    return series_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_full_data(series_data):\n",
    "    with open(\"imdb_data/top_250_series_full.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(series_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a coleta de detalhes adicionais\n",
    "if os.path.exists(\"imdb_data/top_250_series.json\"):\n",
    "    with open(\"imdb_data/top_250_series.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        series_data = json.load(f)\n",
    "    \n",
    "    # Limita a 10 séries para teste (remova para coletar todas)\n",
    "    detailed_series = scrape_series_details(series_data[:10])\n",
    "    save_full_data(detailed_series)\n",
    "    print(\"Detalhes adicionais coletados e salvos com sucesso!\")\n",
    "else:\n",
    "    print(\"Arquivo 'top_250_series.json' não encontrado. Execute primeiro a Tarefa 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza e Transformação de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_transform_data():\n",
    "    if os.path.exists(\"imdb_data/top_250_series_full.json\"):\n",
    "        with open(\"imdb_data/top_250_series_full.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        for serie in data:\n",
    "            # Limpa o título removendo números e caracteres especiais\n",
    "            serie[\"title\"] = re.sub(r'^\\d+\\.\\s*', '', serie[\"title\"]).strip()\n",
    "            \n",
    "            # Converte ano para inteiro\n",
    "            if isinstance(serie[\"year\"], str):\n",
    "                serie[\"year\"] = int(serie[\"year\"]) if serie[\"year\"].isdigit() else serie[\"year\"]\n",
    "            \n",
    "            # Converte episódios para formato numérico quando possível\n",
    "            if isinstance(serie[\"episodes\"], str):\n",
    "                ep_match = re.search(r'(\\d+)', serie[\"episodes\"])\n",
    "                if ep_match:\n",
    "                    serie[\"episodes\"] = int(ep_match.group(1))\n",
    "            \n",
    "            # Garante que a nota seja float\n",
    "            if isinstance(serie[\"rating\"], str):\n",
    "                serie[\"rating\"] = float(serie[\"rating\"]) if serie[\"rating\"].replace('.', '').isdigit() else serie[\"rating\"]\n",
    "        \n",
    "        # Salva os dados limpos\n",
    "        with open(\"imdb_data/top_250_series_clean.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "        print(\"Dados limpos e transformados salvos com sucesso!\")\n",
    "    else:\n",
    "        print(\"Arquivo 'top_250_series_full.json' não encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a limpeza e transformação dos dados\n",
    "clean_and_transform_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpad-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
